{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction to Pytorch _ Linear Regression.ipynb","provenance":[{"file_id":"17KI_GvXl5L195YtfMlaMGhgWdYleFKtH","timestamp":1591840206639},{"file_id":"17OoWbmbWcs-Mf0U6Gt4j_zLhHDnl-4jA","timestamp":1591839422234},{"file_id":"1nxmU5kEoBsHiBzhpQTUz9SSHXH_I5G_o","timestamp":1591575122170}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Gg3d-eylbCHd"},"source":["<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1SctzfeQJDdGN2eMRQhJEoQWWO9rovrWh\" width=\"300\">\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"LeEEOiRhdYZk"},"source":["\n","\n","> Lecture Prepared By: Mir Tafseer Nayeem\n","\n","\n","> Course Teacher: Sanzana Karim Lora\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"T5eyiHwTZNLN"},"source":["## What is Pytorch? \n","\n","[PyTorch](https://pytorch.org/) is a python package built by **Facebook AI Research (FAIR)** that provides two high-level features:\n","- Tensor computation (like numpy) with strong GPU acceleration\n","- Deep Neural Networks built on a tape-based autograd (*Automatic Gradient Calculation*) system\n","\n","## Why Pytorch? \n","- **More Pythonic** \n","    - Flexible\n","    - Intuitive and cleaner code\n","    - Easy to learn & debug\n","    - Dynamic Computation Graph (*network behavior can be changed programmatically at runtime*)\n","\n","- **More Neural Networkic**\n","    - Write code as the network works\n","    - forward/backward\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hd_43_3QTolP"},"source":["## Checking PyTorch version"]},{"cell_type":"code","metadata":{"id":"dQmfkTfSdl_g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627897845306,"user_tz":-360,"elapsed":5088,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"3a0d0776-4801-4ef3-baf6-02a4f8ebf476"},"source":["import torch\n","\n","print(torch.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["1.9.0+cu102\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LnCyI5TsG6l8"},"source":["## Introduction to Tensors\n","\n","A **PyTorch Tensor** is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic **n-dimensional array** to be used for arbitrary **numeric computation**.\n","\n","The biggest difference between a numpy array and a PyTorch Tensor is that a **PyTorch Tensor can run on either CPU or GPU**. To run operations on the GPU, **just cast the Tensor to a cuda datatype**.\n","\n","\n","A scalar is **zero-order tensor** or rank zero tensor. A vector is a **one-dimensional** or first order tensor, and a matrix is a **two-dimensional** or second order tensor. \n","\n","\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1pka-LVyrq_7r0sCm59cvOQofEYAcnO4r\" width=\"550\">\n","</div>\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1zHT5CGzIgpe1aLkdawrllTMn74nYVeAp\" width=\"550\">\n","</div>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5blQSOs56dFu"},"source":["A [torch.Tensor](https://pytorch.org/docs/stable/tensors.html) is a **multi-dimensional matrix** containing elements of a **single data type**.\n","\n","`torch.Tensor` is an alias for the default tensor type (`torch.FloatTensor`)."]},{"cell_type":"code","metadata":{"id":"aJECsFOO_nVd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627898389018,"user_tz":-360,"elapsed":438,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"6cb85204-be3b-4075-d3b1-4c29753bb671"},"source":["torch.tensor([[1., -1.], [1., -1.]])"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1., -1.],\n","        [ 1., -1.]])"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"fkYo6MU5GEE6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627898450767,"user_tz":-360,"elapsed":397,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"43a4f0b8-029a-4140-c6c5-d6c6d41b7a7e"},"source":["x = torch.rand(5, 3)\n","print(x)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tensor([[0.8339, 0.3926, 0.8429],\n","        [0.8542, 0.2441, 0.5415],\n","        [0.6815, 0.7266, 0.7664],\n","        [0.3355, 0.5513, 0.5719],\n","        [0.6114, 0.5199, 0.2966]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v5GntwAR_tdy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627898518509,"user_tz":-360,"elapsed":661,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"98889a1a-2c92-4bf6-ca6e-9f667a229f0a"},"source":["# Converting numpy arrays to tensors\n","import numpy as np\n","torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2, 3],\n","        [4, 5, 6]])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"j6K1HB1DuPc5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627898541300,"user_tz":-360,"elapsed":610,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"620f0c4a-cbb3-439d-ea4f-6b389ae8701f"},"source":["# Converting numpy arrays to tensors\n","np_values = np.array([[1, 2, 3], [4, 5, 6]])\n","\n","tensor_values = torch.from_numpy(np_values)\n","\n","print (tensor_values)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["tensor([[1, 2, 3],\n","        [4, 5, 6]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y9zOrpNc_-yT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627898611315,"user_tz":-360,"elapsed":386,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"9866b5ee-7cf2-44ea-9804-e46bf6332d10"},"source":["# A tensor of specific data type can be constructed by passing a torch.dtype\n","\n","torch.zeros([2, 4], dtype=torch.int32)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 0, 0, 0],\n","        [0, 0, 0, 0]], dtype=torch.int32)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AsIc2tbfD2um","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627898676954,"user_tz":-360,"elapsed":393,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"93461996-4af2-4478-bd68-ced0d9f7775e"},"source":["# The contents of a tensor can be accessed and modified using Python’s indexing and slicing notation:\n","x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","print(x[1][2])\n","\n","# Modify a certain element\n","x[0][1] = 8\n","print(x)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor(6)\n","tensor([[1, 8, 3],\n","        [4, 5, 6]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ixEKku4bEerW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627898717863,"user_tz":-360,"elapsed":398,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"3a36a0cf-3a79-49ce-ddcb-8d90e70531bd"},"source":["# Use torch.Tensor.item() to get a Python number from a tensor containing a single value\n","\n","x = torch.tensor([[1]])\n","print (x)\n","\n","print(x.item())\n","\n","x = torch.tensor(2.5)\n","\n","print(x.item())"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tensor([[1]])\n","1\n","2.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LIqHBWSZEqXc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627898879897,"user_tz":-360,"elapsed":405,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"d8e259a2-7bbc-45e4-e9b6-6bf91b7c17a7"},"source":["x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","print(x.size())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["torch.Size([2, 3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mf5LMRZgORa7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627898917405,"user_tz":-360,"elapsed":390,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"30134e10-01a4-4263-a22b-3349e32c8e70"},"source":["# Tensor addition & subtraction\n","x = torch.rand(5, 3)\n","y = torch.rand(5, 3)\n","\n","print(x)\n","print(y)\n","\n","print(x + y)\n","print(x - y)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["tensor([[0.3372, 0.1064, 0.6366],\n","        [0.5478, 0.9838, 0.4977],\n","        [0.0992, 0.5079, 0.5029],\n","        [0.7117, 0.5295, 0.4463],\n","        [0.1474, 0.8680, 0.7427]])\n","tensor([[0.4912, 0.0074, 0.0748],\n","        [0.6034, 0.6219, 0.2836],\n","        [0.3793, 0.4257, 0.4946],\n","        [0.6077, 0.2988, 0.8947],\n","        [0.0120, 0.3533, 0.4301]])\n","tensor([[0.8284, 0.1138, 0.7114],\n","        [1.1512, 1.6057, 0.7813],\n","        [0.4785, 0.9336, 0.9975],\n","        [1.3194, 0.8283, 1.3410],\n","        [0.1594, 1.2213, 1.1728]])\n","tensor([[-0.1541,  0.0990,  0.5618],\n","        [-0.0556,  0.3618,  0.2140],\n","        [-0.2802,  0.0821,  0.0083],\n","        [ 0.1041,  0.2307, -0.4485],\n","        [ 0.1354,  0.5148,  0.3126]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OEo36NgVOhNc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627898958338,"user_tz":-360,"elapsed":654,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"731cfa70-05d4-4594-d3b3-c8e1b346634a"},"source":["# Syntax 2 for Tensor addition & subtraction in PyTorch\n","print(torch.add(x, y))\n","print(torch.sub(x, y))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["tensor([[0.8284, 0.1138, 0.7114],\n","        [1.1512, 1.6057, 0.7813],\n","        [0.4785, 0.9336, 0.9975],\n","        [1.3194, 0.8283, 1.3410],\n","        [0.1594, 1.2213, 1.1728]])\n","tensor([[-0.1541,  0.0990,  0.5618],\n","        [-0.0556,  0.3618,  0.2140],\n","        [-0.2802,  0.0821,  0.0083],\n","        [ 0.1041,  0.2307, -0.4485],\n","        [ 0.1354,  0.5148,  0.3126]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dGopWgyCO9eB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627899051293,"user_tz":-360,"elapsed":404,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"38a2c2f9-71e7-427a-ca14-9bb39c08ecc3"},"source":["# Tensor Product & Transpose\n","\n","mat1 = torch.randn(2, 3)\n","mat2 = torch.randn(3, 3)\n","\n","print(mat1)\n","print(mat2)\n","\n","print(torch.mm(mat1, mat2))\n","\n","print(mat1.t())"],"execution_count":12,"outputs":[{"output_type":"stream","text":["tensor([[ 0.7037, -0.8629,  0.1056],\n","        [ 0.3302, -0.0438, -0.7206]])\n","tensor([[-1.0071, -0.3935,  0.5050],\n","        [-0.0889, -0.7851, -0.8677],\n","        [-0.0014, -0.8361, -1.0941]])\n","tensor([[-0.6321,  0.3123,  0.9886],\n","        [-0.3276,  0.5070,  0.9932]])\n","tensor([[ 0.7037,  0.3302],\n","        [-0.8629, -0.0438],\n","        [ 0.1056, -0.7206]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tNNdLxAiS6iq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627899144422,"user_tz":-360,"elapsed":432,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"ab2f285b-226d-4dac-9a0a-ccf909041b7e"},"source":["# Elementwise multiplication\n","t = torch.Tensor([[1, 2], [3, 4]])\n","t.mul(t)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.,  4.],\n","        [ 9., 16.]])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"Ien5Sa-sR4Po","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627899193684,"user_tz":-360,"elapsed":421,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"20dbcb32-e29f-4553-f32a-2aaa5b2e3110"},"source":["# Shape, dimensions, and datatype of a tensor object\n","\n","x = torch.rand(5, 3)\n","\n","print('Tensor shape:', x.shape)   # t.size() gives the same\n","print('Number of dimensions:', x.dim())\n","print('Tensor type:', x.type())   # there are other types"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Tensor shape: torch.Size([5, 3])\n","Number of dimensions: 2\n","Tensor type: torch.FloatTensor\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xcRbhDxnSbFl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627899314868,"user_tz":-360,"elapsed":391,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"0b20208b-ec74-4f82-8848-7475d1900f0f"},"source":["# Slicing\n","t = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","\n","# Every row, only the last column\n","print(t[:, -1])\n","\n","# First 2 rows, all columns\n","print(t[:2, :])\n","\n","# Lower right most corner\n","print(t[-1:, -1:])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["tensor([3., 6., 9.])\n","tensor([[1., 2., 3.],\n","        [4., 5., 6.]])\n","tensor([[9.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wWvHVdN_W2tK"},"source":["## Linear Regression\n","\n","### PyTorch Model Designing Steps\n","\n","1.   **Design your model using class with Variables**\n","2.   **Construct loss and optimizer  (select from PyTorch API)**\n","3.   **Training cycle (forward, backward, update)**"]},{"cell_type":"markdown","metadata":{"id":"QyV1hfzhZ4EB"},"source":["### Step #1 : Design your model using class with Variables"]},{"cell_type":"code","metadata":{"id":"dWyCJFyUW2TQ","executionInfo":{"status":"ok","timestamp":1627900213628,"user_tz":-360,"elapsed":368,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}}},"source":["from torch import nn\n","import torch\n","from torch import tensor\n","\n","import matplotlib.pyplot as plt\n","\n","x_data = tensor([[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]])\n","y_data = tensor([[2.0], [4.0], [6.0], [8.0], [10.0], [12.0]])\n","\n","# Hyper-parameters\n","input_size = 1\n","output_size = 1\n","num_epochs = 50\n","learning_rate = 0.01"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"aM_epadwrutJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627899776745,"user_tz":-360,"elapsed":370,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"b9b07101-f013-48ee-d65a-9e0f853186d7"},"source":["print(torch.__version__)\n","\n","print(torch.cuda.get_device_name())"],"execution_count":16,"outputs":[{"output_type":"stream","text":["1.9.0+cu102\n","Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4UTgtmxyqJ1N"},"source":["### Using GPU for the PyTorch Models\n","\n","Remember always 2 things must be on GPU\n","\n","- model\n","- tensors"]},{"cell_type":"code","metadata":{"id":"y6VTdaeqZ_fo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627900231331,"user_tz":-360,"elapsed":12077,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"f346f5e5-c74e-44dd-9930-8121310de72c"},"source":["class Model(nn.Module):\n","    def __init__(self):\n","        \"\"\"\n","        In the constructor we instantiate nn.Linear module\n","        \"\"\"\n","        super().__init__()\n","        self.linear = torch.nn.Linear(input_size, output_size)  # One in and one out\n","\n","    def forward(self, x):\n","        \"\"\"\n","        In the forward function we accept a Variable of input data and we must return\n","        a Variable of output data. We can use Modules defined in the constructor as\n","        well as arbitrary operators on Variables.\n","        \"\"\"\n","        y_pred = self.linear(x)\n","        return y_pred\n","\n","\n","# our model\n","model = Model()\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (linear): Linear(in_features=1, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"_BQ4YlNxnY4m"},"source":["### Explanations:- \n","\n","`torch.nn.Linear(in_features, out_features, bias=True)`\n","\n","Applies a linear transformation to the incoming data: $y = W^T * x + b$\n","\n","**Parameters:**\n","\n","- `in_features `– size of each input sample (i.e. size of x)\n","- `out_features` – size of each output sample (i.e. size of y)\n","- `bias` – If set to False, the layer will not learn an additive bias. **Default: True**\n"]},{"cell_type":"markdown","metadata":{"id":"B67aGn6kaDAh"},"source":["###Step #2 : Construct loss and optimizer (select from PyTorch API)"]},{"cell_type":"code","metadata":{"id":"qj6oN5_daEUI","executionInfo":{"status":"ok","timestamp":1627900934225,"user_tz":-360,"elapsed":389,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}}},"source":["# Construct our loss function and an Optimizer. The call to model.parameters()\n","# in the SGD constructor will contain the learnable parameters\n","criterion = torch.nn.MSELoss(reduction='sum')\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BumRaPT2eApz"},"source":["### Explanations:- \n","\n","MSE Loss: Mean Squared Error (Default: 'mean')\n","\n","- $\\hat y$ :  prediction\n","- $y$ :  true value\n","\n","$MSE \\ (sum) =  \\sum_{i=1}^n(\\hat y_i - y_i)^2$\n","\n","$MSE \\ (mean) = \\frac{1}{n} \\sum_{i=1}^n(\\hat y_i - y_i)^2$"]},{"cell_type":"markdown","metadata":{"id":"2I4ZfKK1uEOl"},"source":["###Step #3 : Training: forward, loss, backward, step"]},{"cell_type":"code","metadata":{"id":"zVZw04-2uGE-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627901907456,"user_tz":-360,"elapsed":456,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"2568c86f-0bad-4d1e-c258-2d23ddfcc780"},"source":["# Credit: https://github.com/jcjohnson/pytorch-examples\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    # 1) Forward pass: Compute predicted y by passing x to the model\n","    y_pred = model(x_data.to(device))\n","\n","    # 2) Compute and print loss\n","    loss = criterion(y_pred, y_data.to(device))\n","    print(f'Epoch: {epoch} | Loss: {loss.item()} ')\n","\n","    # Zero gradients, perform a backward pass, and update the weights.\n","    optimizer.zero_grad()\n","    # Getting gradients w.r.t. parameters\n","    loss.backward()\n","    # Updating parameters\n","    optimizer.step()\n","\n","\n","# After training\n","hour_var = tensor([[7.0]]).to(device)\n","y_pred = model(hour_var)\n","print(\"Prediction (after training)\",  7, model(hour_var).data[0][0].item())"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Epoch: 0 | Loss: 733.8422241210938 \n","Epoch: 1 | Loss: 618.663818359375 \n","Epoch: 2 | Loss: 521.5740356445312 \n","Epoch: 3 | Loss: 439.7317810058594 \n","Epoch: 4 | Loss: 370.74188232421875 \n","Epoch: 5 | Loss: 312.5855407714844 \n","Epoch: 6 | Loss: 263.561279296875 \n","Epoch: 7 | Loss: 222.2346649169922 \n","Epoch: 8 | Loss: 187.3966522216797 \n","Epoch: 9 | Loss: 158.02813720703125 \n","Epoch: 10 | Loss: 133.26995849609375 \n","Epoch: 11 | Loss: 112.39811706542969 \n","Epoch: 12 | Loss: 94.80223083496094 \n","Epoch: 13 | Loss: 79.96781921386719 \n","Epoch: 14 | Loss: 67.46118927001953 \n","Epoch: 15 | Loss: 56.916751861572266 \n","Epoch: 16 | Loss: 48.02642822265625 \n","Epoch: 17 | Loss: 40.53044891357422 \n","Epoch: 18 | Loss: 34.209896087646484 \n","Epoch: 19 | Loss: 28.880212783813477 \n","Epoch: 20 | Loss: 24.385833740234375 \n","Epoch: 21 | Loss: 20.595645904541016 \n","Epoch: 22 | Loss: 17.399076461791992 \n","Epoch: 23 | Loss: 14.702975273132324 \n","Epoch: 24 | Loss: 12.428791046142578 \n","Epoch: 25 | Loss: 10.51031494140625 \n","Epoch: 26 | Loss: 8.891729354858398 \n","Epoch: 27 | Loss: 7.526003837585449 \n","Epoch: 28 | Loss: 6.373469352722168 \n","Epoch: 29 | Loss: 5.400687217712402 \n","Epoch: 30 | Loss: 4.579488754272461 \n","Epoch: 31 | Loss: 3.8861122131347656 \n","Epoch: 32 | Loss: 3.3005313873291016 \n","Epoch: 33 | Loss: 2.8058552742004395 \n","Epoch: 34 | Loss: 2.387855052947998 \n","Epoch: 35 | Loss: 2.0345349311828613 \n","Epoch: 36 | Loss: 1.7357745170593262 \n","Epoch: 37 | Loss: 1.4830436706542969 \n","Epoch: 38 | Loss: 1.2691497802734375 \n","Epoch: 39 | Loss: 1.0880279541015625 \n","Epoch: 40 | Loss: 0.934567928314209 \n","Epoch: 41 | Loss: 0.8044572472572327 \n","Epoch: 42 | Loss: 0.6940627098083496 \n","Epoch: 43 | Loss: 0.6003166437149048 \n","Epoch: 44 | Loss: 0.5206344127655029 \n","Epoch: 45 | Loss: 0.4528375566005707 \n","Epoch: 46 | Loss: 0.39508387446403503 \n","Epoch: 47 | Loss: 0.3458232581615448 \n","Epoch: 48 | Loss: 0.3037465214729309 \n","Epoch: 49 | Loss: 0.2677493095397949 \n","Prediction (after training) 7 13.546892166137695\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZQDkpcGf5C5e"},"source":["### Explanations:- \n","\n","- Calling `.backward()` mutiple times accumulates the gradient (**by addition**) for each parameter. \n","\n","- This is why you should call `optimizer.zero_grad()` after each .step() call. \n","\n","- Note that following the first `.backward` call, a second call is only possible after you have performed another **forward pass**.\n","\n","- `optimizer.step` performs a parameter update based on the current gradient (**stored in .grad attribute of a parameter**)\n","\n","### Simplified equation:-\n","\n","- `parameters = parameters - learning_rate * parameters_gradients`\n","- parameters $W$ and $b$ in ($y = W^T * x + b$)\n","- $\\theta = \\theta - \\eta \\cdot \\nabla_\\theta$  [ General parameter $\\theta$ ]\n","  *  $\\theta$ : parameters (our variables)\n","  *  $\\eta$ : learning rate (how fast we want to learn)\n","  *  $\\nabla_\\theta$ : parameters' gradients\n","\n","  "]},{"cell_type":"markdown","metadata":{"id":"jIjs2MBepwHQ"},"source":["### Plot of predicted and actual values"]},{"cell_type":"code","metadata":{"id":"0JB0tYXsnhy8","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1627902012146,"user_tz":-360,"elapsed":470,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"985e8f31-f173-451a-9d6d-feb904ef3155"},"source":["# Clear figure\n","plt.clf()\n","\n","# Get predictions\n","predictions = model(x_data.to(device)).cpu().detach().numpy()\n","\n","# Plot true data\n","plt.plot(x_data, y_data, 'go', label='True data', alpha=0.5)\n","\n","# Plot predictions\n","plt.plot(x_data, predictions, '--', label='Predictions', alpha=0.5)\n","\n","# Legend and plot\n","plt.legend(loc='best')\n","plt.show()"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"6_nJUj7jBFV-"},"source":["### Saving Model to Directory "]},{"cell_type":"code","metadata":{"id":"2BB9gRPmM624","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627902101378,"user_tz":-360,"elapsed":29633,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"08199aca-3835-436f-ae55-8778e9ef7768"},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","\n","root_path = '/content/gdrive/My Drive/CSE4238/Lecture Contents/Codes/Lab 04/'"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A5YnXE3tN9cu"},"source":["### Save Model"]},{"cell_type":"code","metadata":{"id":"aiOsiWYyBETG","executionInfo":{"status":"ok","timestamp":1627902119181,"user_tz":-360,"elapsed":3621,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}}},"source":["save_model = True\n","\n","if save_model is True:\n","    # Saves only parameters\n","    # wights & biases\n","    torch.save(model.state_dict(), root_path + 'linear_regression.pkl') \n","\n","# Save the model checkpoint \n","# torch.save(model.state_dict(), root_path + 'linear_regression.ckpt')\n"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fhBapRsyN_Vo"},"source":["### Load Model"]},{"cell_type":"code","metadata":{"id":"d_n7589AOGwS","executionInfo":{"status":"ok","timestamp":1627902139809,"user_tz":-360,"elapsed":399,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}}},"source":["load_model = True\n","\n","if load_model is True:\n","    model.load_state_dict(torch.load(root_path + 'linear_regression.pkl'))"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mf8fGQJ9Df05"},"source":["### Try Other Optimizers\n","\n","- torch.optim.Adagrad\n","- torch.optim.Adam\n","- torch.optim.Adamax\n","- torch.optim.ASGD\n","- torch.optim.LBFGS\n","- torch.optim.RMSprop\n","- torch.optim.Rprop\n","- torch.optim.SGD\n"]},{"cell_type":"markdown","metadata":{"id":"XI9xGl0Eog09"},"source":["### *** Official PyTorch Tutorials ***\n","\n","https://pytorch.org/tutorials/"]}]}