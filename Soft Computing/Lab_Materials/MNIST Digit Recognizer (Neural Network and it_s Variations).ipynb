{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST Digit Recognizer (Neural Network and it_s Variations).ipynb","provenance":[{"file_id":"1JXiP9YzF-roL3Vt2UOLYKsRYf2yauTRK","timestamp":1592642571900}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"868b78055ce24120a181c0e215cf5542":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e1d474b8465e46c79ab4817500366230","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d08f1f4fdf4a4f66bd53145c08524941","IPY_MODEL_f29c2d60806142c399623182c3ca0e44"]}},"e1d474b8465e46c79ab4817500366230":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d08f1f4fdf4a4f66bd53145c08524941":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_da3d9fce34f843458446421e719f73b3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9912422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9912422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_43bd88f2fc0c4fde93daefbc99de3902"}},"f29c2d60806142c399623182c3ca0e44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7b06eb5d65074861af1cfd02119a39ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9913344/? [11:10&lt;00:00, 14786.28it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3ec6e4d4a6904af897e8b65337b1fc1c"}},"da3d9fce34f843458446421e719f73b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"43bd88f2fc0c4fde93daefbc99de3902":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b06eb5d65074861af1cfd02119a39ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3ec6e4d4a6904af897e8b65337b1fc1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"550ba35ef7bb4ed4ab981fd360013008":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b8cdcdaaa8c34de1bc8f3405e3cc3b36","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1aa1688610e9416caf57d6be515a2391","IPY_MODEL_b1ec60f669404ff1909aaf10e4f1941e"]}},"b8cdcdaaa8c34de1bc8f3405e3cc3b36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1aa1688610e9416caf57d6be515a2391":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0b8da44ec52b474391e85829e82b4681","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c33a65a8e094f27a67e574d490b6189"}},"b1ec60f669404ff1909aaf10e4f1941e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e31b1585497741a3b1b460bd838f5c5d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [00:06&lt;00:00, 4467.18it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_950d7636921e42888524352092336b93"}},"0b8da44ec52b474391e85829e82b4681":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2c33a65a8e094f27a67e574d490b6189":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e31b1585497741a3b1b460bd838f5c5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"950d7636921e42888524352092336b93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb59b8c6e6d84ce48ade67af0eb4785f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_adb46fb13ba2423f87ab46cb47505c8b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_937f3e47d9704c91b9c944b887b2dee9","IPY_MODEL_95ff9d088262457d9bbcdabfc7050f01"]}},"adb46fb13ba2423f87ab46cb47505c8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"937f3e47d9704c91b9c944b887b2dee9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5c4dbe5e9dc54251ac1eb39b50830b9d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1648877,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1648877,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac1260de4d934ca78fa376286ae619a7"}},"95ff9d088262457d9bbcdabfc7050f01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ad62cfa904cf4ed39a5342d313de07bc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1649664/? [00:03&lt;00:00, 415566.51it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0341e654262c43439e595aab3eab3dab"}},"5c4dbe5e9dc54251ac1eb39b50830b9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ac1260de4d934ca78fa376286ae619a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ad62cfa904cf4ed39a5342d313de07bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0341e654262c43439e595aab3eab3dab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8dbc61459a524335940f0424aa0dea22":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_274ef2ba51474aafaca09393debf0803","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3cff195983dd4324a7aca84513619713","IPY_MODEL_4cc4dd0215ff4a16a1036a12b38dd0ca"]}},"274ef2ba51474aafaca09393debf0803":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3cff195983dd4324a7aca84513619713":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_84916933d3414025b876db60e816268e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4542,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4542,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b4eee2939fb749fb8d77663df6426a5e"}},"4cc4dd0215ff4a16a1036a12b38dd0ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4b58cfa4e6a743438d6dba26f034a7b4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5120/? [10:59&lt;00:00,  7.77it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_168a20b911d944b7bca8216be53af0a7"}},"84916933d3414025b876db60e816268e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b4eee2939fb749fb8d77663df6426a5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b58cfa4e6a743438d6dba26f034a7b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"168a20b911d944b7bca8216be53af0a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"IU2vVOns0lmz"},"source":["\n","\n","> Notebook Prepared by: Mir Tafseer Nayeem\n","\n","\n","> Course Teacher: Sanzana Karim Lora\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"z0tKD3f1Nt8y"},"source":["## MNIST Digit Recognizer (Neural Network)"]},{"cell_type":"markdown","metadata":{"id":"SyzBofWXmt0H"},"source":["\n","\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1VT-muG5HJoWaT9jwlmI6fe_7CjbW9x8I\" width=\"300\">\n","</div>\n","\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1foK0jI3dSuvCBBUbiqVKMiLn7x3ngA_x\" width=\"350\" height=\"200\">\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"7ILa4hbOxdnJ"},"source":["## One Layer FNN with Sigmoid Activation"]},{"cell_type":"code","metadata":{"id":"HJ1dVc9mgbN8","executionInfo":{"status":"ok","timestamp":1628671604859,"user_tz":-360,"elapsed":4864,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o9vfh-4mtXt3"},"source":["<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=16ZWsh6DrrwuzC4stYhsmcpIEGCke33Jc\" width=\"480\">\n","</div>\n"]},{"cell_type":"markdown","metadata":{"id":"EL0F4kOtWER5"},"source":[" - Our input size is determined by the size of the image **(height x width) = (28X28)**. Hence the size of our input is **784 (28 x 28)**.\n","\n"," - When we pass an image to our model, it will try to predict if it's **0, 1, 2, 3, 4, 5, 6, 7, 8, or 9**. That is a total of 10 classes, hence we have an output size of 10.\n","\n"," - Determining the **hidden layer size** is one of the crutial part. The first layer prior to the non-linear layer. This can be any **real number**. A large number of hidden nodes denotes a **bigger model with more parameters**. \n","\n","- The bigger model isn't **always the better model**. On the other hand, bigger model requires **more training samples** to learn and converge to a good model. \n","\n","- Actually a bigger model **requires more training samples** to learn and converge to a good model. Hence, it is wise to pick the model size for the problem at hand. Because it is a simple problem of recognizing digits, we typically would not need a big model to achieve good results.\n","\n","- Moreover, too small of a hidden size would mean there would be **insufficient model capacity to predict competently**. Too small of a capacity denotes a **smaller brain capacity** so no matter how many training samples you provide, it has a maximum capacity boundary in terms of its **predictive power**."]},{"cell_type":"markdown","metadata":{"id":"fXVIydDCxDPS"},"source":["- **Input dimension:**\n","  - Size of image: $28 \\times 28 = 784$\n","\n","- **Output dimension: 10**\n","  - 0, 1, 2, 3, 4, 5, 6, 7, 8, 9"]},{"cell_type":"code","metadata":{"id":"o5hVijghPqz0","executionInfo":{"status":"ok","timestamp":1628672126431,"user_tz":-360,"elapsed":519,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}}},"source":["# Hyperparameters\n","\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100 # num of hidden nodes\n","output_dim = 10\n","\n","learning_rate = 0.1  # More power so we can learn faster! previously it was 0.001\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C4R6x4MvEsOT"},"source":["### Loading MNIST Dataset"]},{"cell_type":"code","metadata":{"id":"eUumuKA-cahD","colab":{"base_uri":"https://localhost:8080/","height":845,"referenced_widgets":["868b78055ce24120a181c0e215cf5542","e1d474b8465e46c79ab4817500366230","d08f1f4fdf4a4f66bd53145c08524941","f29c2d60806142c399623182c3ca0e44","da3d9fce34f843458446421e719f73b3","43bd88f2fc0c4fde93daefbc99de3902","7b06eb5d65074861af1cfd02119a39ba","3ec6e4d4a6904af897e8b65337b1fc1c","550ba35ef7bb4ed4ab981fd360013008","b8cdcdaaa8c34de1bc8f3405e3cc3b36","1aa1688610e9416caf57d6be515a2391","b1ec60f669404ff1909aaf10e4f1941e","0b8da44ec52b474391e85829e82b4681","2c33a65a8e094f27a67e574d490b6189","e31b1585497741a3b1b460bd838f5c5d","950d7636921e42888524352092336b93","fb59b8c6e6d84ce48ade67af0eb4785f","adb46fb13ba2423f87ab46cb47505c8b","937f3e47d9704c91b9c944b887b2dee9","95ff9d088262457d9bbcdabfc7050f01","5c4dbe5e9dc54251ac1eb39b50830b9d","ac1260de4d934ca78fa376286ae619a7","ad62cfa904cf4ed39a5342d313de07bc","0341e654262c43439e595aab3eab3dab","8dbc61459a524335940f0424aa0dea22","274ef2ba51474aafaca09393debf0803","3cff195983dd4324a7aca84513619713","4cc4dd0215ff4a16a1036a12b38dd0ca","84916933d3414025b876db60e816268e","b4eee2939fb749fb8d77663df6426a5e","4b58cfa4e6a743438d6dba26f034a7b4","168a20b911d944b7bca8216be53af0a7"]},"executionInfo":{"status":"ok","timestamp":1628672171829,"user_tz":-360,"elapsed":13981,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"902f9c1f-b7b4-4b03-a570-46b65022ff66"},"source":["'''\n","LOADING DATASET\n","'''\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","'''\n","MAKING DATASET ITERABLE\n","'''\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)  "],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 503: Service Unavailable\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"868b78055ce24120a181c0e215cf5542","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 503: Service Unavailable\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"550ba35ef7bb4ed4ab981fd360013008","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 503: Service Unavailable\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb59b8c6e6d84ce48ade67af0eb4785f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 503: Service Unavailable\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8dbc61459a524335940f0424aa0dea22","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vmkMVvf8CLHf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628672199901,"user_tz":-360,"elapsed":698,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"5750bc8e-7f6d-4c31-a37b-d2c11e01b2bf"},"source":["print(len(train_dataset))\n","print(len(test_dataset))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["60000\n","10000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Isz6lbl4Iovx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628672200403,"user_tz":-360,"elapsed":5,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"e36dc0ca-0742-409e-c51c-d5434c578bf2"},"source":["# One Image Size\n","print(train_dataset[0][0].size())\n","print(train_dataset[0][0].numpy().shape)\n","# First Image Label\n","print(train_dataset[0][1])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["torch.Size([1, 28, 28])\n","(1, 28, 28)\n","5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GQB8tvNUQZop"},"source":["<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1mn8G92moF0MqXhD0J-M7cPidCYXR0hHS\" width=\"680\" height=\"380\">\n","</div>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nRm3MYkW8QVU"},"source":["### Step #1 : Design your model using class"]},{"cell_type":"code","metadata":{"id":"6mydzEXpeu7G","executionInfo":{"status":"ok","timestamp":1628672408119,"user_tz":-360,"elapsed":497,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}}},"source":["class NeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","\n","        ### Non-linearity\n","        self.sigmoid = nn.Sigmoid()\n","\n","        ### Output layer\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        # Linear layer\n","        out  = self.linear_1(x)\n","        # Non-linearity\n","        out = self.sigmoid(out)\n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HIfiAaZB1rJz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628672419551,"user_tz":-360,"elapsed":9452,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"9c5486ff-ec34-4194-cac9-9e2108e0cd39"},"source":["'''\n","INSTANTIATE MODEL CLASS\n","'''\n","model = NeuralNetworkModel(input_size = input_dim,\n","                           num_classes = output_dim,\n","                           num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NeuralNetworkModel(\n","  (linear_1): Linear(in_features=784, out_features=100, bias=True)\n","  (sigmoid): Sigmoid()\n","  (linear_out): Linear(in_features=100, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"pdrDJPOKzdSp"},"source":["###Step #2 : Construct loss and optimizer\n","\n","Unlike linear regression, we do not use MSE here, we need Cross Entropy Loss to calculate our loss before we backpropagate and update our parameters.\n","\n","`criterion = nn.CrossEntropyLoss() ` \n","\n","It does 2 things at the same time.\n","\n","1. Computes softmax ([Logistic or Sigmoid]/softmax function)\n","2. Computes Cross Entropy Loss"]},{"cell_type":"code","metadata":{"id":"GM2q_XGHzcta","executionInfo":{"status":"ok","timestamp":1628672434730,"user_tz":-360,"elapsed":491,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}}},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I2Hb_JQ6AUok"},"source":["###Step #3 : Training: forward, loss, backward, step"]},{"cell_type":"code","metadata":{"id":"Q3Jb4vhRZI9p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628672486935,"user_tz":-360,"elapsed":45210,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"928b849c-9669-4851-bc5c-829b3dd8dc8f"},"source":["'''\n","TRAIN THE MODEL\n","'''\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.5947197079658508. Accuracy: 85.7\n","Iteration: 1000. Loss: 0.3815585672855377. Accuracy: 89.25\n","Iteration: 1500. Loss: 0.4641951024532318. Accuracy: 90.43\n","Iteration: 2000. Loss: 0.3090425729751587. Accuracy: 91.13\n","Iteration: 2500. Loss: 0.29374998807907104. Accuracy: 91.75\n","Iteration: 3000. Loss: 0.24644999206066132. Accuracy: 92.06\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t_5UaSvBJckA"},"source":["## Expanding Neural Network variants\n","\n","2 ways to expand a neural network\n","- Different non-linear activation\n","- More hidden layers"]},{"cell_type":"markdown","metadata":{"id":"sG1A_uEHL5uU"},"source":["## One Layer FNN with Tanh Activation"]},{"cell_type":"code","metadata":{"id":"cyXyrgHMw41l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628672668399,"user_tz":-360,"elapsed":45104,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"837483ec-fb1c-4881-9b7e-6687f60b87ab"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class NeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","\n","        ### Non-linearity\n","        self.tanh = nn.Tanh()\n","\n","        ### Output layer\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        # Linear layer\n","        out  = self.linear_1(x)\n","        # Non-linearity\n","        out = self.tanh(out)\n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","model = NeuralNetworkModel(input_size = input_dim,\n","                           num_classes = output_dim,\n","                           num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.36468505859375. Accuracy: 91.09\n","Iteration: 1000. Loss: 0.25966769456863403. Accuracy: 92.4\n","Iteration: 1500. Loss: 0.18930301070213318. Accuracy: 93.37\n","Iteration: 2000. Loss: 0.30717623233795166. Accuracy: 94.06\n","Iteration: 2500. Loss: 0.1268729567527771. Accuracy: 94.59\n","Iteration: 3000. Loss: 0.20038409531116486. Accuracy: 94.95\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hoxfWq6ZNPiL"},"source":["## One Layer FNN with ReLU Activation"]},{"cell_type":"code","metadata":{"id":"PGVrecUPMsyT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628672741553,"user_tz":-360,"elapsed":46085,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"f61e81c5-e252-4d0b-dbad-35ee434d139d"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class NeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","\n","        ### Non-linearity\n","        self.relu = nn.ReLU()\n","\n","        ### Output layer\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        # Linear layer\n","        out  = self.linear_1(x)\n","        # Non-linearity\n","        out = self.relu(out)\n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","model = NeuralNetworkModel(input_size = input_dim,\n","                           num_classes = output_dim,\n","                           num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.37031885981559753. Accuracy: 91.25\n","Iteration: 1000. Loss: 0.22112388908863068. Accuracy: 93.18\n","Iteration: 1500. Loss: 0.15047088265419006. Accuracy: 94.17\n","Iteration: 2000. Loss: 0.12214329093694687. Accuracy: 94.78\n","Iteration: 2500. Loss: 0.07993905246257782. Accuracy: 95.29\n","Iteration: 3000. Loss: 0.13384516537189484. Accuracy: 95.9\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T_r9Lq-O0FJi"},"source":["## Two Layer FNN with ReLU Activation"]},{"cell_type":"code","metadata":{"id":"YNhAoGbnNasI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628672876309,"user_tz":-360,"elapsed":46108,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"49d538d3-d64c-466e-90cb-21c6f46f4133"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class DeepNeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer: 784 --> 100\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","        ### Non-linearity in 1st hidden layer\n","        self.relu_1 = nn.ReLU()\n","\n","        ### 2nd hidden layer: 100 --> 100\n","        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n","        ### Non-linearity in 2nd hidden layer\n","        self.relu_2 = nn.ReLU()\n","\n","        ### Output layer: 100 --> 10\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        ### 1st hidden layer\n","        out  = self.linear_1(x)\n","        ### Non-linearity in 1st hidden layer\n","        out = self.relu_1(out)\n","        \n","        ### 2nd hidden layer\n","        out  = self.linear_2(out)\n","        ### Non-linearity in 2nd hidden layer\n","        out = self.relu_2(out)\n","        \n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","# INSTANTIATE MODEL CLASS\n","\n","model = DeepNeuralNetworkModel(input_size = input_dim,\n","                               num_classes = output_dim,\n","                               num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","# INSTANTIATE LOSS & OPTIMIZER CLASS\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.5130558609962463. Accuracy: 91.61\n","Iteration: 1000. Loss: 0.14962011575698853. Accuracy: 94.0\n","Iteration: 1500. Loss: 0.12266486883163452. Accuracy: 94.81\n","Iteration: 2000. Loss: 0.06784087419509888. Accuracy: 95.74\n","Iteration: 2500. Loss: 0.11516282707452774. Accuracy: 96.25\n","Iteration: 3000. Loss: 0.10977107286453247. Accuracy: 96.56\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JYdiRLt3FPLy"},"source":["## Three Layer FNN with ReLU Activation"]},{"cell_type":"code","metadata":{"id":"T0jY7KZ0E50C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628673024305,"user_tz":-360,"elapsed":48312,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"94f37f19-3a00-4907-a37a-e865fb01eeae"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 #num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class DeepNeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer: 784 --> 100\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","        ### Non-linearity in 1st hidden layer\n","        self.relu_1 = nn.ReLU()\n","\n","        ### 2nd hidden layer: 100 --> 100\n","        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n","        ### Non-linearity in 2nd hidden layer\n","        self.relu_2 = nn.ReLU()\n","\n","        ### 3rd hidden layer: 100 --> 100\n","        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n","        ### Non-linearity in 3rd hidden layer\n","        self.relu_3 = nn.ReLU()\n","\n","        ### Output layer: 100 --> 10\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        ### 1st hidden layer\n","        out  = self.linear_1(x)\n","        ### Non-linearity in 1st hidden layer\n","        out = self.relu_1(out)\n","        \n","        ### 2nd hidden layer\n","        out  = self.linear_2(out)\n","        ### Non-linearity in 2nd hidden layer\n","        out = self.relu_2(out)\n","\n","        ### 3rd hidden layer\n","        out  = self.linear_3(out)\n","        ### Non-linearity in 3rd hidden layer\n","        out = self.relu_3(out)\n","        \n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","# INSTANTIATE MODEL CLASS\n","\n","model = DeepNeuralNetworkModel(input_size = input_dim,\n","                               num_classes = output_dim,\n","                               num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","# INSTANTIATE LOSS & OPTIMIZER CLASS\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.3637915551662445. Accuracy: 89.02\n","Iteration: 1000. Loss: 0.1974862515926361. Accuracy: 93.9\n","Iteration: 1500. Loss: 0.0671909898519516. Accuracy: 95.43\n","Iteration: 2000. Loss: 0.01938820257782936. Accuracy: 96.14\n","Iteration: 2500. Loss: 0.18320013582706451. Accuracy: 96.33\n","Iteration: 3000. Loss: 0.08768919855356216. Accuracy: 97.12\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-1vTvfpkNjHL"},"source":["## What's Next?\n","\n","- Try with other activations from Pytorch. \n","- Try different activations for different layers (We used ReLU Only)\n","- Try adding more hidden layers \n","- Try increasing the hidden layer neurons (We used 100 here in this example)\n","- Try experimenting with different neurons for different hidden layers (We here in this examples used a fixed sixe: 100)\n","\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1VYlYjGEYo6JKsiADnzOCNM2TPkhNI-Yq\" width=\"230\" height=\"580\">\n","</div>\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1hMrKBdhQ8cmhxGgCzFczQi4xpHMsHufD\" width=\"680\" height=\"280\">\n","</div>\n","\n"]}]}